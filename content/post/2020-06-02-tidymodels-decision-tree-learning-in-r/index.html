---
title: 'Tidymodels: Decision Tree Learning in R'
author: Cianna Bedford-Petersen, Chris Loan & Brendan Cullen
date: '2020-06-02'
output:
    blogdown::html_page:
      toc: TRUE
slug: []
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2020-06-02T10:57:23-07:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---


<div id="TOC">
<ul>
<li><a href="#intro">Intro</a></li>
<li><a href="#setup">Setup</a></li>
<li><a href="#import-the-data">Import the data</a></li>
<li><a href="#explore-the-data">Explore the data</a></li>
<li><a href="#split-data-and-resample">Split data and resample</a></li>
<li><a href="#pre-processing">Pre-processing</a></li>
<li><a href="#create-a-model-and-workflow">Create a model and workflow</a></li>
<li><a href="#fit-the-model">Fit the model</a></li>
<li><a href="#our-3-models">Our 3 models</a><ul>
<li><a href="#bagged-trees">Bagged trees</a><ul>
<li><a href="#specify-model">Specify model</a></li>
<li><a href="#create-workflow">Create workflow</a></li>
<li><a href="#fit-the-model-1">Fit the model</a></li>
<li><a href="#visualize">Visualize</a></li>
</ul></li>
<li><a href="#random-forest">Random forest</a><ul>
<li><a href="#specify-the-model">Specify the model</a></li>
<li><a href="#create-workflow-1">Create workflow</a></li>
<li><a href="#fit-the-model-2">Fit the model</a></li>
<li><a href="#visualize-1">Visualize</a></li>
</ul></li>
<li><a href="#boosted-trees">Boosted trees</a><ul>
<li><a href="#specify-the-model-1">Specify the model</a></li>
<li><a href="#create-workflow-2">Create workflow</a></li>
<li><a href="#fit-the-model-3">Fit the model</a></li>
<li><a href="#visualize-2">Visualize</a></li>
</ul></li>
</ul></li>
<li><a href="#model-evaluation">Model evaluation</a></li>
<li><a href="#apply-model-to-test-data">Apply model to test data</a></li>
</ul>
</div>

<div id="intro" class="section level1">
<h1>Intro</h1>
<p>Tidyverse’s newest release has recently come together to form a cohesive suite of packages for modeling and machine learning. The successor to Max Kuhn’s caret package, tidymodel’s collection of tools allows for a tidy approach to your data from start to finish. We’re going to l, walk through the basics for getting off the ground with tidymodels and demonstrate its application to three different decision tree methods for predicting student test scores. For further information about tidymodels packages and capabilities you can visit <a href="https://www.tidymodels.org/" class="uri">https://www.tidymodels.org/</a>.</p>
</div>
<div id="setup" class="section level1">
<h1>Setup</h1>
<pre class="r"><code>library(tidyverse)
library(tidymodels)
library(tictoc)
library(xgboost)
library(baguette)
library(here)
library(future)
library(vip)</code></pre>
</div>
<div id="import-the-data" class="section level1">
<h1>Import the data</h1>
<pre class="r"><code>set.seed(100)

# import train data
dat &lt;- read_csv(here(&quot;static&quot;, &quot;data&quot;, &quot;train.csv&quot;)) %&gt;% 
  select(-classification) %&gt;%
  sample_frac(.01)

# import fall membership report data
sheets &lt;- readxl::excel_sheets(here(&quot;static&quot;, &quot;data&quot;, &quot;fallmembershipreport_20192020.xlsx&quot;))

ode_schools &lt;- readxl::read_xlsx(here(&quot;static&quot;, &quot;data&quot;, &quot;fallmembershipreport_20192020.xlsx&quot;),
                                 sheet = sheets[4])

# select relevant vars
ethnicities &lt;- ode_schools %&gt;%
  select(attnd_schl_inst_id = `Attending School ID`,
         attnd_dist_inst_id = `Attending District Institution ID`,
         sch_name = `School Name`,
         contains(&quot;%&quot;)) %&gt;%
  janitor::clean_names()

names(ethnicities) &lt;- gsub(&quot;x2019_20_percent&quot;, &quot;p&quot;, names(ethnicities))

# join ethnicity data with original train data
dat &lt;- left_join(dat, ethnicities)

# import free and reduced lunch data
frl &lt;- rio::import(&quot;https://nces.ed.gov/ccd/Data/zip/ccd_sch_033_1718_l_1a_083118.zip&quot;,
              setclass = &quot;tbl_df&quot;)  %&gt;% 
  janitor::clean_names()  %&gt;% 
  filter(st == &quot;OR&quot;)  %&gt;%
  select(ncessch, lunch_program, student_count)  %&gt;% 
  mutate(student_count = replace_na(student_count, 0))  %&gt;% 
  pivot_wider(names_from = lunch_program,
              values_from = student_count)  %&gt;% 
  janitor::clean_names()  %&gt;% 
  mutate(ncessch = as.double(ncessch))

# import student counts for each school across grades
stu_counts &lt;- rio::import(&quot;https://github.com/datalorax/ach-gap-variability/raw/master/data/achievement-gaps-geocoded.csv&quot;,setclass = &quot;tbl_df&quot;)  %&gt;% 
  filter(state == &quot;OR&quot; &amp; year == 1718)  %&gt;% 
  count(ncessch, wt = n)  %&gt;% 
  mutate(ncessch = as.double(ncessch))

# join frl and stu_counts data
frl &lt;- left_join(frl, stu_counts)

# add frl data to train data
dat &lt;- left_join(dat, frl)</code></pre>
</div>
<div id="explore-the-data" class="section level1">
<h1>Explore the data</h1>
<ul>
<li>make VIP plot, then take top 10 and throw into correlation matrix</li>
</ul>
<pre class="r"><code># # remove id variables for VIP plots
# dat_noid &lt;- dat %&gt;% 
#   select(-contains(&quot;id&quot;), -ncessch, -calc_admn_cd, -lang_cd)
# 
# # Produce a plot displaying a rank ordering of variables by their importance
# vip(lm(score ~ ., dat_noid), 
#     mapping = aes(fill = Sign))
# 
# vip(lm(score ~ ., dat), 
#     mapping = aes(fill = Sign))</code></pre>
<ul>
<li>call the data out of the list from VIP</li>
<li>use skimr package</li>
</ul>
</div>
<div id="split-data-and-resample" class="section level1">
<h1>Split data and resample</h1>
<pre class="r"><code>split &lt;- initial_split(dat)
train &lt;- training(split)
cv &lt;- vfold_cv(train)</code></pre>
</div>
<div id="pre-processing" class="section level1">
<h1>Pre-processing</h1>
<pre class="r"><code>rec &lt;- recipe(score ~ ., train) %&gt;% 
  step_mutate(tst_dt = as.numeric(lubridate::mdy_hms(tst_dt))) %&gt;% 
  update_role(contains(&quot;id&quot;), ncessch, new_role = &quot;id vars&quot;) %&gt;% 
  step_nzv(all_predictors(), freq_cut = 0, unique_cut = 0) %&gt;% 
  step_novel(all_nominal()) %&gt;% 
  step_unknown(all_nominal()) %&gt;% 
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role(&quot;id vars&quot;))  %&gt;% 
  step_dummy(all_nominal(), -has_role(&quot;id vars&quot;))</code></pre>
</div>
<div id="create-a-model-and-workflow" class="section level1">
<h1>Create a model and workflow</h1>
</div>
<div id="fit-the-model" class="section level1">
<h1>Fit the model</h1>
</div>
<div id="our-3-models" class="section level1">
<h1>Our 3 models</h1>
<div id="bagged-trees" class="section level2">
<h2>Bagged trees</h2>
<ul>
<li>Introduce model</li>
</ul>
<div id="specify-model" class="section level3">
<h3>Specify model</h3>
<pre class="r"><code>set.seed(100)
mod_bag &lt;- bag_tree() %&gt;%
  set_mode(&quot;regression&quot;) %&gt;%
  set_engine(&quot;rpart&quot;, times = 10) # 10 bootstrap resamples</code></pre>
</div>
<div id="create-workflow" class="section level3">
<h3>Create workflow</h3>
<pre class="r"><code>wflow_bag &lt;- workflow() %&gt;% 
  add_recipe(rec) %&gt;%
  add_model(mod_bag)</code></pre>
</div>
<div id="fit-the-model-1" class="section level3">
<h3>Fit the model</h3>
<pre class="r"><code>set.seed(100)
plan(multisession)

fit_bag &lt;- fit_resamples(
  wflow_bag,
  cv,
  metrics = metric_set(rmse, rsq),
  control = control_resamples(verbose = TRUE,
                              save_pred = TRUE,
                              extract = function(x) extract_model(x)))</code></pre>
</div>
<div id="visualize" class="section level3">
<h3>Visualize</h3>
<p><img src="/post/2020-06-02-tidymodels-decision-tree-learning-in-r/index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
</div>
<div id="random-forest" class="section level2">
<h2>Random forest</h2>
<ul>
<li>Introduce the model</li>
</ul>
<div id="specify-the-model" class="section level3">
<h3>Specify the model</h3>
<pre class="r"><code>set.seed(100)
mod_rf &lt;-rand_forest() %&gt;%
  set_engine(&quot;ranger&quot;,
             num.threads = parallel::detectCores(), #argument from {ranger}
             importance = &quot;permutation&quot;, #argument from {ranger}
             verbose = TRUE) %&gt;% #argument from {ranger}
  set_mode(&quot;regression&quot;) %&gt;% 
  set_args(trees = 1000)</code></pre>
</div>
<div id="create-workflow-1" class="section level3">
<h3>Create workflow</h3>
<pre class="r"><code>wflow_rf &lt;- workflow() %&gt;% 
  add_model(mod_rf) %&gt;% 
  add_recipe(rec)</code></pre>
</div>
<div id="fit-the-model-2" class="section level3">
<h3>Fit the model</h3>
<pre class="r"><code>set.seed(100)
plan(multisession)

fit_rf &lt;- fit_resamples(
  wflow_rf,
  cv,
  metrics = metric_set(rmse, rsq),
  control = control_resamples(verbose = TRUE,
                              save_pred = TRUE,
                              extract = function(x) x)
)</code></pre>
</div>
<div id="visualize-1" class="section level3">
<h3>Visualize</h3>
<p><img src="/post/2020-06-02-tidymodels-decision-tree-learning-in-r/index_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
</div>
<div id="boosted-trees" class="section level2">
<h2>Boosted trees</h2>
<ul>
<li>Introduce the model</li>
</ul>
<div id="specify-the-model-1" class="section level3">
<h3>Specify the model</h3>
<pre class="r"><code>mod_boost &lt;- boost_tree() %&gt;% 
  set_engine(&quot;xgboost&quot;, nthreads = parallel::detectCores()) %&gt;% 
  set_mode(&quot;regression&quot;)</code></pre>
</div>
<div id="create-workflow-2" class="section level3">
<h3>Create workflow</h3>
<pre class="r"><code>wflow_boost &lt;- workflow() %&gt;% 
  add_recipe(rec) %&gt;% 
  add_model(mod_boost)</code></pre>
</div>
<div id="fit-the-model-3" class="section level3">
<h3>Fit the model</h3>
<pre class="r"><code>set.seed(100)
plan(multisession)

fit_boost &lt;- fit_resamples(
  wflow_boost, 
  cv,
  metrics = metric_set(rmse, rsq),
  control = control_resamples(verbose = TRUE,
                              save_pred = TRUE)
)</code></pre>
</div>
<div id="visualize-2" class="section level3">
<h3>Visualize</h3>
<ul>
<li>Probs don’t include graph here, just explain learning rate/what makes boosted trees unique</li>
</ul>
</div>
</div>
</div>
<div id="model-evaluation" class="section level1">
<h1>Model evaluation</h1>
<pre class="r"><code>collect_metrics(fit_bag) %&gt;% 
  bind_rows(collect_metrics(fit_rf)) %&gt;%
  bind_rows(collect_metrics(fit_boost)) %&gt;% 
  filter(.metric == &quot;rmse&quot;) %&gt;% 
  mutate(model = c(&quot;bag&quot;, &quot;rf&quot;, &quot;boost&quot;)) %&gt;% 
  select(model, everything())</code></pre>
<pre><code>## # A tibble: 3 x 6
##   model .metric .estimator  mean     n std_err
##   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 bag   rmse    standard    98.4    10    2.50
## 2 rf    rmse    standard    95.2    10    3.47
## 3 boost rmse    standard    94.8    10    3.09</code></pre>
<ul>
<li>Show metrics in table and rmse/rsq graph</li>
</ul>
</div>
<div id="apply-model-to-test-data" class="section level1">
<h1>Apply model to test data</h1>
<pre class="r"><code># bagged trees
final_fit_bag &lt;- last_fit(
  wflow_bag,
  split = split
)

# random forest
final_fit_rf &lt;- last_fit(
  wflow_rf,
  split = split
)

# boosted trees
final_fit_boost &lt;- last_fit(
  wflow_boost,
  split = split
)

# show performance on test data
collect_metrics(final_fit_bag) %&gt;% 
  bind_rows(collect_metrics(final_fit_rf)) %&gt;%
  bind_rows(collect_metrics(final_fit_boost)) %&gt;% 
  filter(.metric == &quot;rmse&quot;) %&gt;% 
  mutate(model = c(&quot;bag&quot;, &quot;rf&quot;, &quot;boost&quot;)) %&gt;% 
  select(model, everything())</code></pre>
<pre><code>## # A tibble: 3 x 4
##   model .metric .estimator .estimate
##   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 bag   rmse    standard       100. 
## 2 rf    rmse    standard        93.9
## 3 boost rmse    standard        94.2</code></pre>
</div>
