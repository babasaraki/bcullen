---
title: 'Tidymodels: Decision Tree Learning in R'
author: Cianna Bedford-Petersen, Chris Loan & Brendan Cullen
date: '2020-06-02'
slug: []
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2020-06-02T10:57:23-07:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<div id="intro" class="section level1">
<h1>Intro</h1>
<p>Tidyverse’s newest release has recently come together to form a cohesive suite of packages for modeling and machine learning. The successor to Max Kuhn’s caret package, tidymodel’s collection of tools allows for a tidy approach to your data from start to finish. We’re going to l, walk through the basics for getting off the ground with tidymodels and demonstrate its application to three different decision tree methods for predicting student test scores. For further information about tidymodels packages and capabilities you can visit <a href="https://www.tidymodels.org/" class="uri">https://www.tidymodels.org/</a>.</p>
</div>
<div id="setup" class="section level1">
<h1>Setup</h1>
<p>Load both the tidyverse and tidymodel packages into your environment. We’ll also load in the psych package to help us with some descriptives for our data.</p>
<pre class="r"><code>library(here)
library(tidyverse)
library(tidymodels)
library(skimr)
library(xgboost)
library(baguette)
library(future)
library(vip)</code></pre>
</div>
<div id="import-the-data" class="section level1">
<h1>Import the data</h1>
<p>We’re going to be using simulated student test data based on 3rd-8th grade math and reading scores from 189,000 students in the state of Oregon. These data have a variety of student-level variables (e.g. gender, ethnicity, enrollment in special education/talented and gifted programs, etc.) and district-level variables (e.g. school longitude and latitude, proportion of students who qualify for free and reduced-price lunch) to choose from when thinking about what might predict test scores. To highlight the differences in modeling techniques in this tutorial we’re going to include all variables in our analysis. All school IDs in the data are real, so we can use that information to link the data with other sources. Specifically, we’re also going to pull in some free and reduced lunch data from the National Center for Education statistics and some ethnicity data from the Oregon Department of Education. After loading in our three datasets, we’ll join them together to make one cohesive data set and remove any intermediate data sets from our environment. For the purpose of demonstration, we’ll be sampling 1% of the data to keep computer processing time manageable.</p>
<pre class="r"><code>set.seed(100)

# import train data
dat &lt;- read_csv(here(&quot;static&quot;, &quot;data&quot;, &quot;train.csv&quot;)) %&gt;% 
  select(-classification) %&gt;%
  sample_frac(.01)

# import fall membership report data
sheets &lt;- readxl::excel_sheets(here(&quot;static&quot;, &quot;data&quot;, &quot;fallmembershipreport_20192020.xlsx&quot;))

ode_schools &lt;- readxl::read_xlsx(here(&quot;static&quot;, &quot;data&quot;, &quot;fallmembershipreport_20192020.xlsx&quot;),
                                 sheet = sheets[4])

# select relevant vars
ethnicities &lt;- ode_schools %&gt;%
  select(attnd_schl_inst_id = `Attending School ID`,
         attnd_dist_inst_id = `Attending District Institution ID`,
         sch_name = `School Name`,
         contains(&quot;%&quot;)) %&gt;%
  janitor::clean_names()

names(ethnicities) &lt;- gsub(&quot;x2019_20_percent&quot;, &quot;p&quot;, names(ethnicities))

# join ethnicity data with original train data
dat &lt;- left_join(dat, ethnicities)

# import free and reduced lunch data
frl &lt;- rio::import(&quot;https://nces.ed.gov/ccd/Data/zip/ccd_sch_033_1718_l_1a_083118.zip&quot;,
              setclass = &quot;tbl_df&quot;)  %&gt;% 
  janitor::clean_names()  %&gt;% 
  filter(st == &quot;OR&quot;)  %&gt;%
  select(ncessch, lunch_program, student_count)  %&gt;% 
  mutate(student_count = replace_na(student_count, 0))  %&gt;% 
  pivot_wider(names_from = lunch_program,
              values_from = student_count)  %&gt;% 
  janitor::clean_names()  %&gt;% 
  mutate(ncessch = as.double(ncessch))

# import student counts for each school across grades
stu_counts &lt;- rio::import(&quot;https://github.com/datalorax/ach-gap-variability/raw/master/data/achievement-gaps-geocoded.csv&quot;,setclass = &quot;tbl_df&quot;)  %&gt;% 
  filter(state == &quot;OR&quot; &amp; year == 1718)  %&gt;% 
  count(ncessch, wt = n)  %&gt;% 
  mutate(ncessch = as.double(ncessch))

# join frl and stu_counts data
frl &lt;- left_join(frl, stu_counts)

# add frl data to train data
dat &lt;- left_join(dat, frl)</code></pre>
</div>
<div id="explore-the-data" class="section level1">
<h1>Explore the data</h1>
<p>We’ll use the <code>skim()</code> function from the <code>{skimr}</code> package to take a closer look at our (numeric) variables. The histograms show that many of the predictors are highly skewed, but the tree-based models we’ll use below are robust to non-normal data.</p>
<pre class="r"><code>dat %&gt;% 
  select(score, -contains(&quot;id&quot;), -ncessch) %&gt;% 
  select_if(is.numeric) %&gt;% 
  skimr::skim() %&gt;% 
  select(-starts_with(&quot;numeric.p&quot;))</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-3">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">Piped data</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">1894</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">score</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2496.13</td>
<td align="right">115.51</td>
<td align="left">▁▁▂▇▁</td>
</tr>
</tbody>
</table>
<p>While most of our predictors are categorical, we can use <code>{corrplot}</code> to better visualize the relationships among the numeric variables.</p>
<pre class="r"><code>dat %&gt;% 
  select(-contains(&quot;id&quot;), -ncessch, -missing, -not_applicable) %&gt;% 
  select_if(is.numeric) %&gt;% 
  select(score, everything()) %&gt;% 
  cor(use = &quot;complete.obs&quot;) %&gt;% 
  corrplot::corrplot()</code></pre>
<p><img src="/post/2020-06-02-tidymodels-decision-tree-learning-in-r/index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="split-data-and-resample" class="section level1">
<h1>Split data and resample</h1>
<p>The first step of our analysis is to split our data into two separate sets, one for training and one for testing. The training set allows us the flexibility to fit a model and adjust or tune the parameters before evaluating the model’s final performance on our test. We can do this efficiently with the initial_split function. This comes from the rsample package, which is included in the tidymodels package that we loaded earlier. By default this will split your data into 75% for the training set and 25%, but you can change this by setting the prop argument (include a prop argument in our example for clarity). We can also specify the argument strata in order to use stratified sampling. Here, we set strata to our score variable to ensure that our resamples incorporate the full range of scores present in our data (is this what strata does?). Then, we’ll extract the training and the testing data sets from our split object and assign them a name.</p>
<p>Finally, we’ll resample our data using the v-fold command. Though a slightly confusing name, the v-fold command will give us a k-fold cross-validated version of our training data. This will allow us to better estimate the ability of a machine learning model to predict unseen data, this is particularly important if we plan to tune any parameters but also a good choice to prevent overfitting of our model. Though there are many different forms of cross-validation we could apply here, we’ll stick with k-fold as it’s a popular method known for reducing bias in our estimates.</p>
<pre class="r"><code># split the data
split &lt;- initial_split(dat)

# extract the training data
train &lt;- training(split)

# resample the data with 10-fold cross-validation
cv &lt;- vfold_cv(train)</code></pre>
</div>
<div id="pre-processing" class="section level1">
<h1>Pre-processing</h1>
<p>Before we add in our data to the model, we’re going to set up an object that directs our variables into specific roles, this is called a <em>recipe</em>. First, you’ll specify a formula for your model, indicating which variable is your outcome and which are your predictors. Using <code>.</code> here will indicate that we want to use all variables other than <code>score</code> as predictors. Then, we can specify a series of pre-processing steps for our data that directs our recipe to assign our variables a role or manipulates the data.</p>
<p>A complete list of possible pre-processing steps can be found here: <a href="https://recipes.tidymodels.org/articles/Custom_Steps.html" class="uri">https://recipes.tidymodels.org/articles/Custom_Steps.html</a></p>
<pre class="r"><code>rec &lt;- recipe(score ~ ., train) %&gt;% 
  step_mutate(tst_dt = as.numeric(lubridate::mdy_hms(tst_dt))) %&gt;% # convert `tst_dt` variable to a date 
  update_role(contains(&quot;id&quot;), ncessch, new_role = &quot;id vars&quot;) %&gt;% # declare ID variables
  step_nzv(all_predictors(), freq_cut = 0, unique_cut = 0) %&gt;% # remove varaibles with zero variances
  step_novel(all_nominal()) %&gt;% # prepares test data to handle previously unseen factor levels 
  step_unknown(all_nominal()) %&gt;% # categorizes missing categorical data (NA&#39;s) as `unknown`
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role(&quot;id vars&quot;))  %&gt;% # replaces missing numeric observations with the median
  step_dummy(all_nominal(), -has_role(&quot;id vars&quot;)) # dummy codes categorical variables</code></pre>
</div>
<div id="create-a-model" class="section level1">
<h1>Create a model</h1>
<p>The last step before bringing in our data is to specify our model. This will call upon functions from the parsnip package which standardizes language for specifying a multitude of statistical models. There are a few core elements that you will need to specify for each model</p>
<p>The type of model - this indicates what type of model you choose to fit, each of which will be a different function. We’ll be focusing on decision tree methods using bag_tree(), random_forest(), and boost_tree(). A full list of models can be found here <a href="https://www.tidymodels.org/find/parsnip/" class="uri">https://www.tidymodels.org/find/parsnip/</a></p>
<p>The engine - set_engine() calls the package to support the model you specified above.</p>
<p>The mode - set_mode() indicates the type of prediction you’d like to use in your model, you’ll choose between regression and classification. Since we are looking to predict student scores, which is a continuous predictor, we’ll be choosing regression.</p>
<p>The arguments - set_args() allows you to set values for various parameters for your model, each model type will have a specific set of parameters that can be altered. For these parameters, you can either set a particular value or you can use the tune function to search for the optimal value of each parameter. Tuning requires a few extra steps, so we will leave the default arguments for clarity. For more information on tuning check out ???</p>
</div>
<div id="create-a-workflow" class="section level1">
<h1>Create a workflow</h1>
<p>Up to this point we’ve been setting up a lot of individual elements and now it is time to combine them to create a cohesive framework, called a workflow, so we can run our desired models. First, we’ll use the workflow command and then, we’ll pullin the recipe and model we already created. Below are three examples of specifying models and creating a workflow for different decision tree methods.</p>
</div>
<div id="model-examples" class="section level1">
<h1>Model Examples</h1>
<div id="bagged-trees" class="section level2">
<h2>Bagged trees</h2>
<p>A bagged tree approach creates multiple subsets of data from the training set which are randomly chosen with replacement. Each subset of data is used to train a given decision tree. In the end, we have an ensemble of different models. The predictions from all the different trees are averaged together giving us a stronger prediction than one tree alone could.</p>
<div id="specify-model" class="section level3">
<h3>Specify model</h3>
<pre class="r"><code>set.seed(100)
mod_bag &lt;- bag_tree() %&gt;%
  set_mode(&quot;regression&quot;) %&gt;%
  set_engine(&quot;rpart&quot;, times = 10) # 10 bootstrap resamples</code></pre>
</div>
<div id="create-workflow" class="section level3">
<h3>Create workflow</h3>
<pre class="r"><code>wflow_bag &lt;- workflow() %&gt;% 
  add_recipe(rec) %&gt;%
  add_model(mod_bag)</code></pre>
</div>
<div id="fit-the-model" class="section level3">
<h3>Fit the model</h3>
<pre class="r"><code>set.seed(100)
plan(multisession)

fit_bag &lt;- fit_resamples(
  wflow_bag,
  cv,
  metrics = metric_set(rmse, rsq),
  control = control_resamples(verbose = TRUE,
                              save_pred = TRUE,
                              extract = function(x) extract_model(x)))</code></pre>
</div>
<div id="visualize" class="section level3">
<h3>Visualize</h3>
<ul>
<li>The plot below shows counts of each tree’s root node.</li>
</ul>
<p><img src="/post/2020-06-02-tidymodels-decision-tree-learning-in-r/index_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
</div>
<div id="random-forest" class="section level2">
<h2>Random forest</h2>
<p>Random forest is similar to bagged tree methodology but goes one step further. In addition to taking random subsets of data, the model also draws a random selection of features. Instead of utilizing all features, the random subset of features allows more predictors to be eligible root nodes. This is particularly useful for handling high dimensionality data.</p>
<div id="specify-the-model" class="section level3">
<h3>Specify the model</h3>
<pre class="r"><code>set.seed(100)
mod_rf &lt;-rand_forest() %&gt;%
  set_engine(&quot;ranger&quot;,
             num.threads = parallel::detectCores(), #argument from {ranger}
             importance = &quot;permutation&quot;, #argument from {ranger}
             verbose = TRUE) %&gt;% #argument from {ranger}
  set_mode(&quot;regression&quot;) %&gt;% 
  set_args(trees = 1000)</code></pre>
</div>
<div id="create-workflow-1" class="section level3">
<h3>Create workflow</h3>
<pre class="r"><code>wflow_rf &lt;- workflow() %&gt;% 
  add_model(mod_rf) %&gt;% 
  add_recipe(rec)</code></pre>
</div>
<div id="fit-the-model-1" class="section level3">
<h3>Fit the model</h3>
<pre class="r"><code>set.seed(100)
plan(multisession)

fit_rf &lt;- fit_resamples(
  wflow_rf,
  cv,
  metrics = metric_set(rmse, rsq),
  control = control_resamples(verbose = TRUE,
                              save_pred = TRUE,
                              extract = function(x) x)
)</code></pre>
</div>
<div id="visualize-1" class="section level3">
<h3>Visualize</h3>
<p><img src="/post/2020-06-02-tidymodels-decision-tree-learning-in-r/index_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
</div>
</div>
<div id="boosted-trees" class="section level2">
<h2>Boosted trees</h2>
<p>Boosted trees are a type of additive model that makes predictions by combining decisions from a sequence of base models. These models are learned in succession with the first learners fitting simple models and then analyzing data for errors, with the goal of solving for the net error from the prior tree.</p>
<div id="specify-the-model-1" class="section level3">
<h3>Specify the model</h3>
<pre class="r"><code>mod_boost &lt;- boost_tree() %&gt;% 
  set_engine(&quot;xgboost&quot;, nthreads = parallel::detectCores()) %&gt;% 
  set_mode(&quot;regression&quot;)</code></pre>
</div>
<div id="create-workflow-2" class="section level3">
<h3>Create workflow</h3>
<pre class="r"><code>wflow_boost &lt;- workflow() %&gt;% 
  add_recipe(rec) %&gt;% 
  add_model(mod_boost)</code></pre>
</div>
<div id="fit-the-model-2" class="section level3">
<h3>Fit the model</h3>
<pre class="r"><code>set.seed(100)
plan(multisession)

fit_boost &lt;- fit_resamples(
  wflow_boost, 
  cv,
  metrics = metric_set(rmse, rsq),
  control = control_resamples(verbose = TRUE,
                              save_pred = TRUE)
)</code></pre>
</div>
<div id="visualize-2" class="section level3">
<h3>Visualize</h3>
<ul>
<li>Probs don’t include graph here, just explain learning rate/what makes boosted trees unique</li>
</ul>
</div>
</div>
</div>
<div id="model-evaluation" class="section level1">
<h1>Model evaluation</h1>
<p>After running these three models, it’s time to evaluate their performance. We can do this with <code>tune::collect_metrics()</code>.</p>
<pre class="r"><code>collect_metrics(fit_bag) %&gt;% 
  bind_rows(collect_metrics(fit_rf)) %&gt;%
  bind_rows(collect_metrics(fit_boost)) %&gt;% 
  filter(.metric == &quot;rmse&quot;) %&gt;% 
  mutate(model = c(&quot;bag&quot;, &quot;rf&quot;, &quot;boost&quot;)) %&gt;% 
  select(model, everything()) %&gt;% 
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">model</th>
<th align="left">.metric</th>
<th align="left">.estimator</th>
<th align="right">mean</th>
<th align="right">n</th>
<th align="right">std_err</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">bag</td>
<td align="left">rmse</td>
<td align="left">standard</td>
<td align="right">98.42890</td>
<td align="right">10</td>
<td align="right">2.504904</td>
</tr>
<tr class="even">
<td align="left">rf</td>
<td align="left">rmse</td>
<td align="left">standard</td>
<td align="right">95.20828</td>
<td align="right">10</td>
<td align="right">3.466279</td>
</tr>
<tr class="odd">
<td align="left">boost</td>
<td align="left">rmse</td>
<td align="left">standard</td>
<td align="right">94.82690</td>
<td align="right">10</td>
<td align="right">3.094577</td>
</tr>
</tbody>
</table>
<ul>
<li>Show metrics in table and rmse/rsq graph</li>
</ul>
</div>
<div id="apply-model-to-test-data" class="section level1">
<h1>Apply model to test data</h1>
<p>The final step is to apply the model we have chosen to our test data.</p>
<pre class="r"><code># bagged trees
final_fit_bag &lt;- last_fit(
  wflow_bag,
  split = split
)

# random forest
final_fit_rf &lt;- last_fit(
  wflow_rf,
  split = split
)

# boosted trees
final_fit_boost &lt;- last_fit(
  wflow_boost,
  split = split
)</code></pre>
<pre class="r"><code># show performance on test data
collect_metrics(final_fit_bag) %&gt;% 
  bind_rows(collect_metrics(final_fit_rf)) %&gt;%
  bind_rows(collect_metrics(final_fit_boost)) %&gt;% 
  filter(.metric == &quot;rmse&quot;) %&gt;% 
  mutate(model = c(&quot;bag&quot;, &quot;rf&quot;, &quot;boost&quot;)) %&gt;% 
  select(model, everything()) %&gt;% 
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">model</th>
<th align="left">.metric</th>
<th align="left">.estimator</th>
<th align="right">.estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">bag</td>
<td align="left">rmse</td>
<td align="left">standard</td>
<td align="right">99.99022</td>
</tr>
<tr class="even">
<td align="left">rf</td>
<td align="left">rmse</td>
<td align="left">standard</td>
<td align="right">93.86375</td>
</tr>
<tr class="odd">
<td align="left">boost</td>
<td align="left">rmse</td>
<td align="left">standard</td>
<td align="right">94.24961</td>
</tr>
</tbody>
</table>
</div>
<div id="conclusions" class="section level1">
<h1>Conclusions</h1>
</div>
